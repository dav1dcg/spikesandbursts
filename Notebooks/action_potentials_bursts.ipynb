{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9ef1ac-37c0-4683-87cd-3f47ca7037df",
   "metadata": {},
   "source": [
    "# Burst detection of action potentials\n",
    "\n",
    "In this tutorial, I will explain how to analyze bursts of action potentials using Python. To read the full tutorial, please see [Patch-clamp data analysis in Python: bursts of action potentials](https://spikesandbursts.wordpress.com/2023/08/24/patch-clamp-data-analysis-in-python-bursts/) of [Spikes and Bursts](https://spikesandbursts.wordpress.com/) blog.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae22fc7-a4c5-49e1-a6dc-748417db02a2",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceced6aa-6f92-4963-9afe-a62214831eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pyabf\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# If you want to display interactive plots using the ipympl backend:\n",
    "# %matplotlib widget \n",
    "# Ipympl creates multiple interactive plots so you need to close them:\n",
    "# plt.close('all') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e15da1-b882-4a91-a101-0d63e492d7aa",
   "metadata": {},
   "source": [
    "# Example data\n",
    "\n",
    "Example data is the file **stg_pd_bursts.abf**. The file is a segment of the file \"877_093_0003\" from [Haley et al., 2018](https://elifesciences.org/articles/41877): https://osf.io/r7aes/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2c7634-e063-47e1-9525-5557372c6456",
   "metadata": {},
   "source": [
    "# Create the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ce1ee-35dd-4f92-8b4f-3cccec46ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_name = 'action_potentials_bursts'\n",
    "\n",
    "# Data path to 'Data_example' folders. Change accordingly to your data structure.\n",
    "data_path = os.path.dirname(os.getcwd())  # Moves one level up from the current directory\n",
    "\n",
    "# Change the folder names accordingly\n",
    "paths = {'data':  f'{data_path}/Data',\n",
    "         'processed_data': f'{data_path}/Processed_data/{notebook_name}',\n",
    "         'analysis': f'{data_path}/Analysis/{notebook_name}'}\n",
    "\n",
    "# Make folders if they do not exist yet\n",
    "for path in paths.values():\n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c1912d-9e00-4168-9ba9-801d094f3fc5",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef201055-9a01-4c86-997b-ecaef77d00b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABF file/s\n",
    "filename = \"stg_pd_bursts\"\n",
    "\n",
    "data_path = f\"{paths['data']}/{filename}.abf\" \n",
    "abf = pyabf.ABF(data_path)\n",
    "print(abf)\n",
    "\n",
    "# Sampling rate\n",
    "fs = int(abf.dataPointsPerMs * 1000)\n",
    "\n",
    "# Quick plot to see the trace/s\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "for sweepNumber in abf.sweepList:\n",
    "    abf.setSweep(sweepNumber)\n",
    "    plt.plot(abf.sweepX, abf.sweepY)\n",
    "    plt.ylabel(abf.sweepLabelY)\n",
    "    plt.xlabel(abf.sweepLabelX)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Select the sweep and/or channel\n",
    "# abf.setSweep(10)  # Sweep\n",
    "# abf.setSweep(sweepNumber=0, channel=0)  # Sweep and channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c664796b-7275-413b-95f5-4d2dc4322f7e",
   "metadata": {},
   "source": [
    "# Pre-process the signal: filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4e55c3-d461-47b9-a5ae-5123a06ad350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling rate\n",
    "fs = int(abf.dataPointsPerMs * 1000)\n",
    "\n",
    "# Lowpass Bessel filter\n",
    "b_lowpass, a_lowpass = signal.bessel(4,     # Order of the filter\n",
    "                                     2000,  # Cutoff frequency\n",
    "                                     'low', # Type of filter\n",
    "                                     analog=False,  # Analog or digital filter\n",
    "                                     norm='phase',  # Critical frequency normalization\n",
    "                                     fs=fs)  # fs: sampling frequency\n",
    "\n",
    "signal_filtered = signal.filtfilt(b_lowpass, a_lowpass, abf.sweepY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420f9607-ad91-4218-88ab-53d242d269b2",
   "metadata": {},
   "source": [
    "# Find Peaks\n",
    "\n",
    "To select a range within the race you have to slice the slice the peaks_signal and time. E.g. `peaks_signal = abf.sweepY[50000:100000]` and `time = abf.sweepX[50000:100000]`. If you want the absolute peak times, add the amount of time you substracted (e.g., 50000/fs). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f358b092-a549-4081-b6b6-b869676b0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the variables here to simplify the code\n",
    "time = abf.sweepX\n",
    "peaks_signal = abf.sweepY  # Or signal_filtered\n",
    "\n",
    "# Set parameters for the Find peaks function (set to None if not needed)\n",
    "thresh_min = -25                    # Min threshold to detect spikes\n",
    "thresh_prominence = 15              # Min spike amplitude  \n",
    "thresh_min_width = 0.5 * (fs/1000)  # Min required width in ms\n",
    "distance_min = 1 * (fs/1000)        # Min horizontal distance between peaks\n",
    "pretrigger_window = (1.5 * fs)/1000\n",
    "posttrigger_window = (2 * fs)/1000\n",
    "\n",
    "# Find peaks function\n",
    "peaks, peaks_dict = find_peaks(peaks_signal, \n",
    "           height=thresh_min, \n",
    "           threshold=thresh_min,  \n",
    "           distance=distance_min,  \n",
    "           prominence=thresh_prominence,  \n",
    "           width=thresh_min_width, \n",
    "           wlen=None,       # Window length to calculate prominence\n",
    "           rel_height=0.5,  # Relative height at which the peak width is measured\n",
    "           plateau_size=None)\n",
    " \n",
    "# Create table with results\n",
    "spikes_table = pd.DataFrame(columns = ['spike', 'spike_index', 'spike_time',\n",
    "                                       'inst_freq', 'isi_s',\n",
    "                                       'width', 'rise_half_ms', 'decay_half_ms',\n",
    "                                       'spike_peak', 'spike_amplitude'])\n",
    "\n",
    "spikes_table.spike = np.arange(1, len(peaks) + 1)\n",
    "spikes_table.spike_index = peaks\n",
    "spikes_table.spike_time = peaks / fs  # Divided by fs to get s\n",
    "spikes_table.isi_s = np.diff(peaks, axis=0, prepend=peaks[0]) / fs\n",
    "spikes_table.inst_freq = 1 / spikes_table.isi_s\n",
    "spikes_table.width = peaks_dict['widths']/(fs/1000) # Width (ms) at half-height\n",
    "spikes_table.rise_half_ms = (peaks - peaks_dict['left_ips'])/(fs/1000) \n",
    "spikes_table.decay_half_ms = (peaks_dict['right_ips'] - peaks)/(fs/1000)\n",
    "spikes_table.spike_peak = peaks_dict['peak_heights']  # height parameter is needed\n",
    "spikes_table.spike_amplitude = peaks_dict['prominences']  # prominence parameter is needed\n",
    "     \n",
    "# Plot the detected spikes in the trace\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(time, peaks_signal)\n",
    "\n",
    "# Red dot on each detected spike\n",
    "ax.plot(peaks/fs, peaks_signal[peaks], \"r.\")\n",
    "\n",
    "# Add a number to each detected peak\n",
    "# for i, txt in enumerate(spikes_table.spike):  \n",
    "#     ax1.annotate(spikes_table.spike[i], (peaks[i]/fs, peaks_signal[peaks][i]))\n",
    "\n",
    "ax.set_title(\"Event detection\")  \n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Voltage (mV)\")\n",
    "# ax.axes.set_xlim(0, 10000)  # Zoom in the trace\n",
    "\n",
    "# Save the plot and the table\n",
    "fig.savefig(f\"{paths['analysis']}/{filename}_spikes_plot.png\", dpi=300)\n",
    "spikes_table.to_csv(f\"{paths['analysis']}/{filename}_spikes_results.csv\", index=False)\n",
    "\n",
    "# Show graph and table\n",
    "plt.show()\n",
    "spikes_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592916bf-cb6e-4eea-a82f-3eca7c0e39fd",
   "metadata": {},
   "source": [
    "# Estimate the interspike intervals of bursts\n",
    "\n",
    "Visually inspect the histogram to identify the two firing modes and the valley between them, and quantify how simmetrical is the distribution using:\n",
    "\n",
    "* [Cumulative moving average](https://pmc.ncbi.nlm.nih.gov/articles/PMC3378047/).\n",
    "* [scipy.stats.skew](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skew.html) quantifies how symmetrical the distribution is. Symmetrical distribution (skew = 0), asymmetrical with long right tail (positive skew), asymmetrical with long left tail (negative skew). Skew > 1 or <-1 is substantial.\n",
    "* [scipy.stats.kurtosis](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kurtosis.html) quantifies whether the tails of the data distribution matches the Gaussian distribution. Kurtosis of 0 (gaussian), negative (fewer tail values than gaussian), positive (more values in the tails than gaussian). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de8c45-b5df-4303-86ee-5547bc84a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign ISI data to this variable\n",
    "hist_data = spikes_table['isi_s']\n",
    "\n",
    "# Empty DataFrame for histogram stats\n",
    "hist_stats = pd.DataFrame()\n",
    "\n",
    "# Bin size\n",
    "bin_size = 10  # in miliseconds\n",
    "\n",
    "# Histogram\n",
    "isi_range = np.ptp(hist_data)\n",
    "bins = int((isi_range * 1000 / bin_size) + 0.5)  # Round to the nearest integer\n",
    "hist = np.histogram(hist_data, bins=bins)\n",
    "hist_counts = hist[0]\n",
    "hist_bins = hist[1]\n",
    "\n",
    "# Cumulative moving average\n",
    "cum = np.cumsum(hist_counts)  # Cumulative sum\n",
    "cma = cum / np.arange(1, len(cum) + 1)\n",
    "\n",
    "# Calculate peaks and valleys of the cma\n",
    "cma_peaks_indexes = scipy.signal.argrelextrema(cma, np.greater)\n",
    "cma_valleys_indexes = scipy.signal.argrelextrema(cma, np.less)\n",
    "\n",
    "# Select the peak you're interested in\n",
    "peak_index = cma_peaks_indexes[0][0]  # Change second number to select the peak\n",
    "alpha = cma[peak_index] * 0.5  # Half-peak, adapt the value to your threshold criterion\n",
    "\n",
    "# Calculate cma_threshold_index relative to the selected cma_peak\n",
    "cma_threshold = (np.argmin(cma[peak_index:] >= alpha) + peak_index) * bin_size/1000 \n",
    "\n",
    "# Dataframe with histogram statistics\n",
    "length = len(hist_stats)\n",
    "hist_stats.loc[length, 'mean_isi'] = np.mean(hist_data)\n",
    "hist_stats.loc[length, 'median_isi'] = np.median(hist_data)\n",
    "hist_stats.loc[length, 'kurtosis'] = kurtosis(hist_counts)\n",
    "hist_stats.loc[length, 'skewness'] = skew(hist_counts, bias=True)\n",
    "hist_stats.loc[length, 'cma_threshold'] = cma_threshold\n",
    "hist_stats.loc[length, 'cma_valley_time'] = cma_valleys_indexes[0][1] * bin_size/1000  # Change peak index as needed\n",
    "hist_stats.loc[length, 'cma_peak_time'] = cma_peaks_indexes[0][0] * bin_size/1000  # Change peak index as needed\n",
    "\n",
    "# Plot ISI histogram\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.set_title(\"ISI histogram\") \n",
    "ax.hist(hist_data, bins=bins, alpha=0.6)\n",
    "\n",
    "# Plot CMA\n",
    "cma_x = np.linspace(np.min(hist_bins), np.max(hist_bins), bins)\n",
    "ax.plot(cma_x, cma)\n",
    "\n",
    "# Plot CMA threshold line\n",
    "ax.axvline(cma_threshold, linestyle=\"dotted\", color=\"gray\")\n",
    "\n",
    "# Plot CMA valleys\n",
    "ax.plot(cma_x[cma_valleys_indexes], cma[cma_valleys_indexes], 'ko')\n",
    "ax.plot(cma_x[cma_peaks_indexes], cma[cma_peaks_indexes], 'mo')\n",
    "\n",
    "# ax.set_xscale('log')  # Logarithmic scale may be easier to set the threshold\n",
    "ax.set_xlabel(\"Time bins (s)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "\n",
    "# Save the table and the plot\n",
    "fig.savefig(f\"{paths['analysis']}/{filename}_isi_plot.png\", dpi=300)  # or svg\n",
    "hist_stats.to_csv(f\"{paths['analysis']}/{filename}_isi_stats.csv\", index=False)\n",
    "\n",
    "# Show graph and table\n",
    "plt.show()\n",
    "hist_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d8476a-6173-4204-81b3-44ada7201f97",
   "metadata": {},
   "source": [
    "# Burst detection: Maximum interval method\n",
    "\n",
    "The function `detect_bursts` takes the Pandas DataFrame with event parameters detected by `FindPeaks` and calculates bursts of events. The function uses the MaxInterval algorithm (see [Cotterill et al., 2016](https://pubmed.ncbi.nlm.nih.gov/27098024/)) to detect bursts with a minimum number of spikes and minimum interburst interval.  \n",
    "\n",
    "The function sorts the input DataFrame by spike positions, creates a new column for burst labels, and iterates through the spikes to assign them to bursts. The function then filters out any bursts with fewer spikes than the minimum required, and calculates burst information by grouping the spikes by burst label. Finally, it returns a DataFrame containing burst information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8690ebc-4fba-4ea1-a676-278c2820d92a",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c91402-70df-4784-8a56-16edf2c815e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def burst_detection(df, spike_times, spike_amplitudes, spike_peaks,\n",
    "                    n_spikes, \n",
    "                    max_isi, \n",
    "                    # min_duration,  # Optional\n",
    "                    min_ibi):\n",
    "    \n",
    "    \"\"\"\n",
    "    Detects bursts in spike data based on spike times, \n",
    "    by identifying consecutive spikes that fulfill the criteria of:\n",
    "    minimum number of spikes, maximum interspike interval, and minimum interburst interval.\n",
    "    \n",
    "    Arguments: \n",
    "        df: DataFrame with spike data.\n",
    "        spike_times: Column name for spike positions.\n",
    "        spike_amplitudes: Column name for spike amplitudes.\n",
    "        spike_peaks: Column name for spike peak amplitudes. \n",
    "        n_spikes: Minimum number of spikes within a burst.\n",
    "        max_isi: Max interspike interval within the burst.\n",
    "        min_duration: Minimum burst duration.\n",
    "        min_ibi: Minimum interburst interval (optional).\n",
    "        \n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with burst information.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.sort_values(by=spike_times)  # Sort DataFrame by spike positions\n",
    "    df['burst'] = np.nan  # Create column for burst labels\n",
    "    burst_num = 0        # Initialize burst number\n",
    "    burst_start = None   # Initialize burst start position\n",
    "    last_spike = None    # Initialize last spike position\n",
    "\n",
    "    for i, row in df.iterrows():  # Loop through DataFrame rows \n",
    "        spike = row[spike_times]   # Extract the spike position \n",
    "        \n",
    "        if burst_start is None:   # It checks if it is the first spike \n",
    "            burst_start = spike   # It marks the current spike position as the start of a burst\n",
    "            last_spike = spike    # Update the last_spike position to the current spike position\n",
    "            df.at[i, 'burst'] = burst_num   # Assign burst number\n",
    "        elif spike - last_spike <= max_isi:  # It checks if the current spike is within max isi\n",
    "            df.at[i, 'burst'] = burst_num  \n",
    "            last_spike = spike \n",
    "        elif spike - last_spike > min_ibi:  # It checks if the interburst interval has been reached\n",
    "            burst_num += 1  \n",
    "            burst_start = spike \n",
    "            last_spike = spike  \n",
    "            df.at[i, 'burst'] = burst_num  \n",
    "    \n",
    "    # Filter bursts with less than min_spikes\n",
    "    df = df[df.groupby('burst')[spike_times].transform('count') >= n_spikes]\n",
    "    \n",
    "    # Filter burst shorter that min_duration (min_duration parameter)\n",
    "    # df = df[df.groupby('burst')[spike_times].transform('max') \n",
    "    #         - df.groupby('burst')[spike_times].transform('min')\n",
    "    #         >= min_duration]\n",
    "    \n",
    "    # Calculate burst information by aggregating single spike information\n",
    "    bursts = df.groupby('burst')[spike_times].agg(['min', 'max', 'count'])\n",
    "    bursts.columns = ['burst_start', 'burst_end', 'spikes_in_bursts']\n",
    "    bursts['burst_length'] = bursts['burst_end'] - bursts['burst_start']\n",
    "    bursts['avg_spike_amplitude'] = df.groupby('burst')[spike_amplitudes].mean()\n",
    "    bursts['avg_spike_peaks'] = df.groupby('burst')[spike_peaks].mean()  \n",
    "    bursts['spikes_frequency'] = bursts['spikes_in_bursts'] / bursts['burst_length']\n",
    "    bursts = bursts.reset_index()\n",
    "    bursts['burst_number'] = bursts.index + 1\n",
    "    \n",
    "    \n",
    "    return bursts[['burst_number', 'burst_start', 'burst_end', \n",
    "                   'burst_length', 'spikes_in_bursts', 'avg_spike_amplitude', \n",
    "                   'avg_spike_peaks', 'spikes_frequency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe531d-1a46-4926-a2d2-14c3ddcf5c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(burst_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f013912f-9ef9-4c7e-8338-d34c27e5c0df",
   "metadata": {},
   "source": [
    "## Table and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b39cc5-8bd4-4942-9dd0-d45c8fab9284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burst table\n",
    "bursts = burst_detection(spikes_table,  # Dataframe with spike positions as input data  \n",
    "                         'spike_time', \n",
    "                         'spike_amplitude',\n",
    "                         'spike_peak',\n",
    "                         n_spikes = 2,  \n",
    "                         max_isi = 0.1,\n",
    "                         # min_duration = 0.5,  # Optional\n",
    "                         min_ibi = 0.2)  \n",
    "\n",
    "\n",
    "# Plotting: create figure and axis\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6))\n",
    "\n",
    "# Plot 1: trace and detected bursts\n",
    "ax1.plot(time, peaks_signal, color='gray')\n",
    "# Plot red dots for detected events\n",
    "ax1.scatter(spikes_table['spike_time'], spikes_table['spike_peak'], color=\"magenta\", s=10)\n",
    "\n",
    "# Plot the detected bursts \n",
    "for i, burst in bursts.iterrows():\n",
    "    burst_start = burst['burst_start']\n",
    "    burst_end = burst['burst_end']\n",
    "    burst_number = int(burst['burst_number'])\n",
    "    \n",
    "    # Set the height of the burst line\n",
    "    # spike_peaks = burst['avg_spike_peaks'] + 5  # Option A\n",
    "    spike_peaks = np.median(spikes_table.spike_peak) + 5  # Option B\n",
    "    \n",
    "    # Plot an horizontal line from beginning to the end of the bursts\n",
    "    ax1.plot([burst_start, burst_end], [spike_peaks, spike_peaks], 'black')\n",
    "    # Annotate each line with the burst number\n",
    "    ax1.annotate(str(burst_number),  xy=(burst_start, spike_peaks), \n",
    "                xytext=(burst_start, spike_peaks + 1))\n",
    "\n",
    "# Set title and show plot\n",
    "ax1.set_title(\"Burst detection\") \n",
    "ax1.set_ylabel(\"Voltage (mV)\")\n",
    "ax1.set_xlabel(\"Time (s)\")\n",
    "\n",
    "# Remove top and right frame borders\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.axes.set_xlim(0, 4)  # OptionaL: Zoom in the trace\n",
    "\n",
    "# Plot 2: single burst \n",
    "ax2.set_title(\"Burst viewer\")\n",
    "burst_number = 2  # Change here the burst number\n",
    "\n",
    "# Plot the signal with detected spikes\n",
    "ax2.plot(time, peaks_signal, color='gray', label=burst_number)\n",
    "ax2.scatter(spikes_table['spike_time'], spikes_table['spike_peak'], color=\"magenta\", s=10)\n",
    "\n",
    "# Burst time window + 0.1 s before and after\n",
    "burst_start = bursts.loc[bursts['burst_number'] == burst_number, 'burst_start'].values[0]\n",
    "burst_end = bursts.loc[bursts['burst_number'] == burst_number, 'burst_end'].values[0]\n",
    "burst_line_y = bursts.loc[bursts['burst_number'] == burst_number, 'avg_spike_peaks'].values[0] + 5\n",
    "ax2.plot([burst_start, burst_end], [burst_line_y, burst_line_y], 'black')\n",
    "ax2.set_xlim(burst_start - 0.1, burst_end + 0.1) \n",
    "\n",
    "# Label the plot\n",
    "ax2.set_ylabel(\"Voltage (mV)\")\n",
    "ax2.set_xlabel(\"Time (s)\")\n",
    "ax2.legend()\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save plot and table\n",
    "fig.savefig(f\"{paths['analysis']}/{filename}_bursts_plot.png\", dpi=300)  # or svg\n",
    "bursts.to_csv(f\"{paths['analysis']}/{filename}_bursts_results.csv\", index=False)\n",
    "\n",
    "# Display the plots and table\n",
    "plt.show()\n",
    "bursts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a1981-5033-4836-a302-3487889b8eb3",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4014d25-2bdf-4c47-92d1-6d35b4a9ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "burst_number = len(bursts)\n",
    "spikes_in_bursts = np.sum(bursts.spikes_in_bursts)\n",
    "spikes_bursts_pct = (spikes_in_bursts / len(spikes_table.spike)) * 100\n",
    "mean_burst_duration = np.mean(bursts.burst_length)\n",
    "\n",
    "# Create a DataFrame \n",
    "bursts_stats = pd.DataFrame({\n",
    "    'Recording': filename,\n",
    "    'Number of bursts': [burst_number],\n",
    "    'Spikes in Bursts': [spikes_in_bursts],\n",
    "    'Spikes in Bursts (%)': [spikes_bursts_pct],\n",
    "    'Mean Burst Duration': [mean_burst_duration]\n",
    "})\n",
    "\n",
    "# Save plot and table\n",
    "bursts_stats.to_csv(f\"{paths['analysis']}/{filename}_bursts_stats.csv\", index=False)\n",
    "\n",
    "bursts_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
