{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def4612e-bef4-4441-98d3-7889bcac96e8",
   "metadata": {},
   "source": [
    "# Animate time series data\n",
    "\n",
    "In this tutorial, I explain how to animate traces from patch-clamp recordings. The full tutorial for this notebook can be found in [Patch-clamp data analysis in Python: animate time series data](https://spikesandbursts.wordpress.com/2024/01/04/patch-clamp-data-analysis-animate-time-series/) of the [Spikes and Bursts](https://spikesandbursts.wordpress.com/) blog.\n",
    "\n",
    "Interactive plots in Jupyter lab using `%matplotlib widget` ([Magic matplotlib](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-matplotlib))\n",
    "\n",
    "Libraries specific to this notebook:\n",
    "* [pyABF](https://github.com/swharden/pyABF)\n",
    "* [MoviePy](https://zulko.github.io/moviepy/)\n",
    "* [Scipy wavfile](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.write.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18d9a77-45af-473a-ba86-923b176ef981",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da4fa32-9866-4d30-aa92-c29e908a0333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for numpy arrays and data tables\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Import abf files\n",
    "import pyabf\n",
    "\n",
    "# Find Peaks and audio functions\n",
    "import scipy\n",
    "from scipy import signal  # Filtering\n",
    "from scipy.signal import find_peaks  # Find Peaks function\n",
    "from scipy.io.wavfile import write  # Audio from NumPy array\n",
    "\n",
    "# Plots and animations\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import animation\n",
    "\n",
    "# Merge video and audio files\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "\n",
    "# Interactive plots in Jupyter lab\n",
    "%matplotlib widget  \n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d10a44-d66e-41d2-9ba1-dab4cfff067c",
   "metadata": {},
   "source": [
    "# Create paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3f9c5-ac83-4be3-9b6d-2abc2dffc5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_name = 'time-series_animations'\n",
    "\n",
    "# Data path to 'Data_example' folders. Change accordingly to your data structure.\n",
    "data_path = os.path.dirname(os.getcwd())  # Moves one level up from the current directory\n",
    "\n",
    "# Change the folder names accordingly\n",
    "paths = {'data':  f'{data_path}/Data',\n",
    "         'processed_data': f'{data_path}/Processed_data/{notebook_name}',\n",
    "         'analysis': f'{data_path}/Analysis/{notebook_name}'}\n",
    "\n",
    "# Make folders if they do not exist yet\n",
    "for path in paths.values():\n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ef3088-9085-42de-b7ca-89f3f97fb91f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load data\n",
    "\n",
    "Examples files:\n",
    "- ABF: **pfc_lhx6_cell-attached.abf** and **mesc_nkx2_aps.abf**\n",
    "- TXT: **pfc_lhx6_cell-attached.txt**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07268ad4-f3b8-43f3-becd-bfdf02508a46",
   "metadata": {},
   "source": [
    "## ABF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b02e96c-e10c-4b3c-9696-b7f04748895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out this cell to check and load the raw .txt data file\n",
    "\n",
    "# ABF file/s\n",
    "recording = \"pfc_lhx6_cell-attached\"  # or \"pfc_lhx6_cell-attached\"\n",
    "\n",
    "data_path = f\"{paths['data']}/{recording}.abf\" \n",
    "abf = pyabf.ABF(data_path)\n",
    "print(abf)\n",
    "\n",
    "# Sampling rate\n",
    "fs = int(abf.dataPointsPerMs * 1000)\n",
    "\n",
    "# Quick plot to see the trace/s\n",
    "plt.figure(figsize=(6,3))\n",
    "\n",
    "# To select channel/sweep: abf.setSweep(sweepNumber=0, channel=0)\n",
    "for sweepNumber in abf.sweepList:  # Only 1 sweep in the example\n",
    "    abf.setSweep(sweepNumber)\n",
    "    y_variable = abf.sweepY\n",
    "    time = abf.sweepX\n",
    "    \n",
    "    # Plot\n",
    "    plt.plot(time, y_variable)\n",
    "    plt.ylabel(abf.sweepLabelY)\n",
    "    plt.xlabel(abf.sweepLabelX)\n",
    "\n",
    "# Print the sampling rate\n",
    "print(\"Sampling rate:\", fs)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()  # Adjust the padding around the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96290bd2-c1c3-43a5-abc2-97f67c6fa5ee",
   "metadata": {},
   "source": [
    "## TXT files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50344e91-3dfe-4bf4-945f-3aec1ad8a1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment this cell to check and load the raw .txt data file\n",
    "# recording = \"pfc_lhx6_cell-attached\" \n",
    "\n",
    "# # Load the text file (note: uses tab '\\t' as the delimiter)\n",
    "# df = pd.read_csv(f\"{paths['data']}/{recording}.txt\", delimiter=\"\\t\")\n",
    "\n",
    "# # Extract columns\n",
    "# time = df.iloc[:, 0] \n",
    "# y_variable = df.iloc[:, 1]\n",
    "\n",
    "# # Convert to NumPy arrays\n",
    "# time = time.to_numpy()\n",
    "# y_variable = y_variable.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d62f0-bd91-4a75-bf3f-27861c7f9afe",
   "metadata": {},
   "source": [
    "# Filter the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177b7d2-3c18-432e-80be-f59f81bd0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowpass Bessel filter\n",
    "b_lowpass, a_lowpass = signal.bessel(4,     # Order of the filter\n",
    "                                     2000,  # Cutoff frequency\n",
    "                                     'low', # Type of filter\n",
    "                                     analog=False,  # Analog or digital filter\n",
    "                                     norm='phase',  # Critical frequency normalization\n",
    "                                     fs=fs)  # fs: sampling frequency\n",
    "\n",
    "signal_filtered = signal.filtfilt(b_lowpass, a_lowpass, y_variable)\n",
    "\n",
    "# Adjust the baseline if needed\n",
    "# signal_filtered = signal_filtered - np.median(signal_filtered)\n",
    "\n",
    "# Simple plot\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "ax.plot(time, signal_filtered)\n",
    "plt.xlabel(abf.sweepLabelX)\n",
    "plt.ylabel(abf.sweepLabelY)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a5c0dc-6d69-4b61-bb90-9df111c6c88a",
   "metadata": {},
   "source": [
    "# Find peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052c791-79f8-4224-8806-4a015228859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the variables here to simplify the code\n",
    "# time = abf.sweepX\n",
    "y_variable = signal_filtered  # Raw or filtered signal\n",
    "\n",
    "# Threshold for peak detection (absolute value)\n",
    "peaks_theshold = 50\n",
    "\n",
    "# Find peaks function\n",
    "peaks, peaks_dict = find_peaks(-y_variable,  # Note: change the polarity of signal for negative peaks\n",
    "                               height=peaks_theshold)\n",
    "\n",
    "# Plot the detected spikes in the trace\n",
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "ax.plot(time, y_variable)\n",
    "\n",
    "# Red dot for each detected spike\n",
    "ax.plot(peaks/fs, y_variable[peaks], \"r.\")\n",
    "ax.set_xlabel(abf.sweepLabelX)\n",
    "ax.set_ylabel(abf.sweepLabelY)\n",
    "\n",
    "fig.tight_layout()  # Adjust layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d3fe91-9d08-41f1-8a76-6f344d207722",
   "metadata": {},
   "source": [
    "# Animate the trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c7800-e2a2-4687-9b6c-d14fb2c32111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the plot\n",
    "fig, ax = plt.subplots(figsize=(8, 3)) \n",
    "\n",
    "# Define plot parameters\n",
    "line, = ax.plot([], [], lw=1, color='tab:blue')  # Initialize a line plot\n",
    "events, = ax.plot([], [], 'o', color='magenta', markersize=3)  # Optional: detected events\n",
    "\n",
    "# Axis options\n",
    "ax.set_xlabel(abf.sweepLabelX)  # Set x-axis label\n",
    "ax.set_ylabel(\"Current (pA)\")  # You can also use 'abf.sweepLabelY'\n",
    "ax.set_xlim(np.min(time), np.max(time))  # Set x-axis limits \n",
    "\n",
    "# Set y-axis limits with some upper and bottom blank space\n",
    "ax.set_ylim(np.min(y_variable) + (0.15 * np.min(y_variable)), \n",
    "            np.max(y_variable) + (0.1 * np.max(y_variable)))  \n",
    "\n",
    "# Animation function\n",
    "interval = 400  # Adapt to your data fs\n",
    "\n",
    "def animate(frame):\n",
    "    end_frame = (frame + 1) * interval  # End frame for each update in the animation\n",
    "    line.set_data(time[:end_frame], y_variable[:end_frame])  # Update line plot data\n",
    "\n",
    "    # Comment out the 'events' lines if you do not want to show detected peaks\n",
    "    events_time = time[peaks[peaks < end_frame]]  # Extract event times\n",
    "    events_signal = y_variable[peaks[peaks < end_frame]]\n",
    "    events.set_data([events_time], [np.min(y_variable[peaks]) * 1.05])  # Event dots at fixed height\n",
    "    # events.set_data(events_time, events_signal * 1.1)  # Event dots at variable heights\n",
    "    \n",
    "    return line, events\n",
    "\n",
    "# Create the animation\n",
    "frames = len(time) // interval\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, frames=frames,\n",
    "                               interval=5, blit=True, repeat=False)\n",
    "\n",
    "print(\"Animation (number of frames):\", frames)\n",
    "\n",
    "fig.tight_layout()  # Adjust layout\n",
    "plt.show()  # Display the animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9fb1ac-8b61-41b9-a564-dccb9082c414",
   "metadata": {},
   "source": [
    "# Save the animated trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d645e1-8dfd-4ff1-8023-da545dab9b70",
   "metadata": {},
   "source": [
    "## Save as mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75caaa-05b8-4843-9303-a2d36cef727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Animation parameters\n",
    "duration_s = 10  # Select the length of the video here\n",
    "\n",
    "anim_fps = frames/duration_s\n",
    "\n",
    "# Save as mp4 \n",
    "extra_args = [\n",
    "    '-vcodec', 'libx264',  # Video codec\n",
    "    '-s', '2400x900',]  # Set the output resolution, same ratio as figure size\n",
    "\n",
    "# Create the video with FFMpegWriter\n",
    "writer = animation.FFMpegWriter(fps=anim_fps, bitrate=3000, \n",
    "                                codec=\"h264\",  extra_args=extra_args)\n",
    "\n",
    "# Save path\n",
    "anim.save(f\"{paths['analysis']}/{recording}_video.mp4\", writer=writer)\n",
    "\n",
    "# Print the fps and duration of the final video\n",
    "print('Video_duration (s):', frames/anim_fps)\n",
    "print('Video_fps:', anim_fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ec5ceb-4978-424a-b7aa-da72b26a222a",
   "metadata": {},
   "source": [
    "## Save as gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc361cb-3224-4fa6-b1d5-bdffed67f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "writergif = animation.PillowWriter(fps=anim_fps, bitrate=2000)\n",
    "\n",
    "anim.save(f\"{paths['analysis']}/{recording}_video.gif\", writer=writergif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a01fac-c956-4d4f-90ab-4dac0c9dd0a5",
   "metadata": {},
   "source": [
    "# Create audio\n",
    "\n",
    "* [Scipy wavfile](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.write.html)\n",
    "* [Soundfile](https://pysoundfile.readthedocs.io/en/latest/)\n",
    "* [IPython display](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e97fd-ef46-4801-993b-8e6669b32695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio parameters\n",
    "amplitude = np.iinfo(np.int16).max  # Get the max value of the audio type (e.g. 16 bits)\n",
    "audio_fs = int(len(y_variable)/duration_s)\n",
    "gain = 1  # Set to 1 if not needed\n",
    "\n",
    "# Normalize the ephys data in the range [-1, 1]\n",
    "normalized_data = y_variable / np.max(np.abs(y_variable))\n",
    "\n",
    "# Scale data option 1: to the audio range and, optionally, multiply by some gain\n",
    "# scaled_data = np.int16(normalized_data * amplitude * gain)\n",
    "\n",
    "# Scale data option 2: clipping the data to get less background noise\n",
    "scaled_data = np.int16(np.clip(normalized_data, -1, -0.06) * amplitude * gain)\n",
    "\n",
    "# Save the NumPy array as a WAV file\n",
    "write(f\"{paths['analysis']}/{recording}_audio.wav\", rate=audio_fs, data=scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bccf63-416a-4b42-8e9c-edc1ff7d04f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, save audio with soundfile or IPython\n",
    "\n",
    "# from IPython.display import Audio\n",
    "# import soundfile as sf\n",
    "\n",
    "# sf.write(f\"{paths['analysis']}/{recording}_audio.wav\", \n",
    "#          scaled_data, audio_fs, subtype='PCM_16')\n",
    "\n",
    "# You can also try to converty directly the time-series data\n",
    "# Audio(y_variable, rate=audio_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080df3ed-4eec-4bdb-8757-2fee8cdb8311",
   "metadata": {},
   "source": [
    "# Animation: merge audio and video\n",
    "\n",
    "Merge audio and video using the library [MoviePy](https://zulko.github.io/moviepy/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f7852-a019-49d7-bf1d-86c77e4df21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Load the video and audio files\n",
    "video_clip = VideoFileClip(f\"{paths['analysis']}/{recording}_video.mp4\")\n",
    "audio_clip = AudioFileClip(f\"{paths['analysis']}/{recording}_audio.wav\")\n",
    "\n",
    "# Set the audio of the video clip\n",
    "video_clip = video_clip.set_audio(audio_clip)\n",
    "\n",
    "# Save the video\n",
    "# save_path = f'path/to/file/{experiment_id}_merge.mp4'\n",
    "save_path = f\"{paths['analysis']}/{recording}_merge.mp4\"\n",
    "\n",
    "video_clip.write_videofile(save_path, \n",
    "                           codec='libx264', bitrate='3000k',\n",
    "                           audio_codec='aac', temp_audiofile='temp_audio.m4a', \n",
    "                           remove_temp=True)\n",
    "\n",
    "# Close the clips\n",
    "video_clip.close()\n",
    "audio_clip.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
